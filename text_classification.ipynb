{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classification",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b4ded438d34645ffb4febf7a5d316f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e43ec4c07bcb4aa4a44a42e0d461d558",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_29a42f9fe7a649ba89c74aa5f6ec95c4",
              "IPY_MODEL_2f36d8b377e74d6093559c9b867fdf98"
            ]
          }
        },
        "e43ec4c07bcb4aa4a44a42e0d461d558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "29a42f9fe7a649ba89c74aa5f6ec95c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b3d0fbdeb18b42b5ac833501cc3c357d",
            "_dom_classes": [],
            "description": "Epoch 1: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2547,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2547,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb4726eb46554e39b582453b6115edd4"
          }
        },
        "2f36d8b377e74d6093559c9b867fdf98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9e27aa20e739497e9624f9542a5bd197",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2547/2547 [01:39&lt;00:00, 25.65it/s, loss=0.000736, v_num=1, train_loss_step=0.000648, train_loss_epoch=0.000883]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b80e3ff9c1544e7a72e4c15473adb29"
          }
        },
        "b3d0fbdeb18b42b5ac833501cc3c357d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb4726eb46554e39b582453b6115edd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e27aa20e739497e9624f9542a5bd197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b80e3ff9c1544e7a72e4c15473adb29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shikha-aggarwal/researchpaperlikes/blob/main/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co19qCLP3Sis"
      },
      "source": [
        "#### 1. Install and Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOsHUjgdIrIW"
      },
      "source": [
        "!pip install datasets transformers pytorch-lightning --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul82czF7JjdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e594aae9-b28d-49da-8703-c725a08eabbf"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "import transformers\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    AutoConfig,\n",
        "    AdamW,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import argparse\n",
        "import random\n",
        "import time\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import RandomSampler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Colab accessing Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uZ_id5d0bbq",
        "outputId": "1d2d95f2-9b04-4cc0-d8a8-a6d5dbf7a540"
      },
      "source": [
        "cd '/content/drive/My Drive/Colab Notebooks/research paper/'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/research paper\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrBQdvUJfSNy"
      },
      "source": [
        "from datasets import load_dataset\n",
        "from ml_project.data_loaders import load_data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPRbBNbIrIl"
      },
      "source": [
        "####2. Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsm-EaDnKFp_"
      },
      "source": [
        "data_dir = './data'\n",
        "tags_list = load_data.load_tags(data_dir)\n",
        "article_tags_2d_list = load_data.load_article_tags(data_dir)\n",
        "user_items_2d_np = load_data.load_user_article_likes(data_dir)\n",
        "articles_df, user_article_likes_2d_np = load_data.load_articles_and_user_article_likes(data_dir)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOydXR-mgfZb"
      },
      "source": [
        "articles_df[\"tags\"] = article_tags_2d_list"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRLJ2xDd2ItH",
        "outputId": "40ee26ba-d971-49a5-a863-fc19e4169800"
      },
      "source": [
        "articles_df.columns"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['doc.id', 'title', 'citeulike.id', 'raw.title', 'raw.abstract', 'tags'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiQ67rcA2DcL"
      },
      "source": [
        "articles_df.rename(columns = {'doc.id': 'doc_id',\n",
        "                              'citeulike.id': 'citeulike_id',\n",
        "                              'raw.title': 'raw_title',\n",
        "                              'raw.abstract': 'raw_abstract'}, \n",
        "                              inplace = True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IovhtAXT2g1B",
        "outputId": "251fb344-ef3e-4cc2-e793-f2596df71978"
      },
      "source": [
        "articles_df.columns"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['doc_id', 'title', 'citeulike_id', 'raw_title', 'raw_abstract', 'tags'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "869WmizMRJWa"
      },
      "source": [
        "train_df, validate_df, test_df = np.split(articles_df.sample(frac=1, random_state=42), \n",
        "                       [int(.6*len(articles_df)), int(.8*len(articles_df))])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P3xD98R3eoQ"
      },
      "source": [
        "####3. Various constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n2gkLHVVhuc"
      },
      "source": [
        "input_length = 100\n",
        "MODEL_CHECKPOINT = 'distilbert-base-uncased'\n",
        "saved_models_path = '/content/drive/MyDrive/Colab Notebooks/research paper/saved_models'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMfcudgK3jgH"
      },
      "source": [
        "#### 4. Dataset class for trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nkigcuGQued"
      },
      "source": [
        "class ArticlesDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df, tokenizer, input_length):\n",
        "        self.pandas_df = df\n",
        "        self.tokenizer = tokenizer        \n",
        "        self.input_length = input_length\n",
        "  \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pandas_df)\n",
        "    \n",
        "\n",
        "    def clean_text(self, text):\n",
        "        text = text.replace('\\n','')\n",
        "        text = text.replace('``', '')\n",
        "        text = text.replace('\"', '')\n",
        "        \n",
        "        return text\n",
        "    \n",
        "\n",
        "    def convert_to_features(self, example_batch):\n",
        "        sentence_1 = self.clean_text(example_batch['raw_title'] + \\\n",
        "                                     example_batch['raw_abstract'])  \n",
        "        source = self.tokenizer.batch_encode_plus([sentence_1], \n",
        "                                                  max_length=self.input_length,\n",
        "                                                  padding='max_length',\n",
        "                                                  truncation=True,\n",
        "                                                  return_tensors=\"pt\")\n",
        "        \n",
        "        return source\n",
        "  \n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        if torch.is_tensor(index):\n",
        "            index = index.tolist()\n",
        "\n",
        "        num_classes = len(tags_list)\n",
        "        source = self.convert_to_features(self.pandas_df.iloc[index])\n",
        "        \n",
        "        source_ids = source[\"input_ids\"].squeeze()\n",
        "        src_mask    = source[\"attention_mask\"].squeeze()\n",
        "        tags = self.pandas_df.iloc[index]['tags']\n",
        "\n",
        "        indices = [0] * len(tags_list)\n",
        "        for tag in tags:\n",
        "            indices[tag] = 1\n",
        "        \n",
        "        return {\"input_ids\": source_ids, \"attention_mask\": src_mask, \"label\": torch.tensor(indices, dtype=torch.float)}"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "545PP3o8IrJV"
      },
      "source": [
        "#### 5. PyTorch Lightning Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZwo62X8rO8g"
      },
      "source": [
        "class DistilbertFineTuner(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, hparams):\n",
        "        super(DistilbertFineTuner, self).__init__()\n",
        "        self.save_hyperparameters(hparams)\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.hparams.tokenizer_name_or_path)\n",
        "        self.model = AutoModel.from_pretrained(self.hparams.tokenizer_name_or_path)\n",
        "        self.config_used = AutoConfig.from_pretrained(self.hparams.tokenizer_name_or_path)\n",
        "        self.linear_layer = nn.Linear(self.config_used.dim, self.config_used.dim)\n",
        "        self.classifier_layer = nn.Linear(self.config_used.dim, self.hparams.output_dims)\n",
        "        self.dropout = nn.Dropout(self.config_used.seq_classif_dropout)\n",
        "\n",
        "        self.model_dir = self.hparams.model_dir\n",
        "        \n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels):\n",
        "        distilbert_output = self.model(\n",
        "            input_ids = input_ids,\n",
        "            attention_mask = attention_mask\n",
        "            )\n",
        "        hidden_state = distilbert_output[0]  # (batch, seq_len, dim)\n",
        "        pooled_output = hidden_state[:, 0]  # Take the last output (batch, dim)\n",
        "        pooled_output = self.linear_layer(pooled_output)\n",
        "        pooled_output = nn.ReLU()(pooled_output)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier_layer(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.MSELoss()\n",
        "            loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss = loss,\n",
        "            logits = logits,\n",
        "            hidden_states = distilbert_output.hidden_states,\n",
        "            attentions = distilbert_output.attentions,\n",
        "        )\n",
        "\n",
        "\n",
        "    def _step(self, batch):\n",
        "        outputs = self.forward(\n",
        "            input_ids = batch['input_ids'],\n",
        "            attention_mask = batch['attention_mask'],\n",
        "            labels = batch['label']\n",
        "        )\n",
        "        loss = outputs[0]\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss = self._step(batch)\n",
        "        self.log('train_loss', loss, on_step = True, on_epoch = True, \n",
        "                 prog_bar = True, logger = True)\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        train_dataset = ArticlesDataset(train_df,\n",
        "                                        self.tokenizer,\n",
        "                                        input_length = input_length)\n",
        "        sampler = RandomSampler(train_dataset)\n",
        "\n",
        "        dataloader = DataLoader(train_dataset,\n",
        "                                sampler = sampler,\n",
        "                                batch_size = self.hparams.train_batch_size,\n",
        "                                drop_last = True,\n",
        "                                num_workers = 2)\n",
        "        return dataloader\n",
        "\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        validation_dataset = ArticlesDataset(validate_df,\n",
        "                                             self.tokenizer,\n",
        "                                             input_length = input_length)\n",
        "        sampler = RandomSampler(validation_dataset)\n",
        "\n",
        "        return DataLoader(validation_dataset,\n",
        "                          batch_size = self.hparams.eval_batch_size,\n",
        "                          sampler = sampler,\n",
        "                          num_workers = 2)\n",
        "    \n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        ## Set bias decay to zero\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": self.hparams.weight_decay,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "            },]\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, lr = self.hparams.learning_rate)\n",
        "        # decreasing learning rate (linear) after increasing in num_warmup_steps\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer = optimizer,\n",
        "            num_warmup_steps = self.hparams.warmup_steps,\n",
        "            num_training_steps = self.hparams.training_steps\n",
        "        )\n",
        "        self.lr_scheduler = scheduler\n",
        "        self.log('configured optimizer: ', optimizer)\n",
        "        return optimizer"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1MqxBJQ4N2B"
      },
      "source": [
        "#### 6. Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0WWmkX9s59N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426,
          "referenced_widgets": [
            "b4ded438d34645ffb4febf7a5d316f87",
            "e43ec4c07bcb4aa4a44a42e0d461d558",
            "29a42f9fe7a649ba89c74aa5f6ec95c4",
            "2f36d8b377e74d6093559c9b867fdf98",
            "b3d0fbdeb18b42b5ac833501cc3c357d",
            "fb4726eb46554e39b582453b6115edd4",
            "9e27aa20e739497e9624f9542a5bd197",
            "1b80e3ff9c1544e7a72e4c15473adb29"
          ]
        },
        "outputId": "867751c4-45fb-460d-daba-d7d357fe42c0"
      },
      "source": [
        "args_dict = dict(\n",
        "    model_dir               = saved_models_path,\n",
        "    model_name_or_path      = 'distilbert-base-uncased',\n",
        "    tokenizer_name_or_path  = 'distilbert-base-uncased',\n",
        "    # num_labels              = len(tags_list),\n",
        "    output_dims             = len(tags_list),\n",
        "    learning_rate           = 1e-5,\n",
        "    weight_decay            = 0.0,\n",
        "    adam_epsilon            = 1e-8,\n",
        "    warmup_steps            = 0,\n",
        "    train_batch_size        = 4,\n",
        "    eval_batch_size         = 4,\n",
        "    num_train_epochs        = 2,\n",
        "    accumulate_grad_batches = 10,\n",
        "    training_steps          = 10000,\n",
        "    n_gpu                   = 1,\n",
        "    resume_from_checkpoint  = None,\n",
        "    val_check_interval      = 0.5, \n",
        "    early_stop_callback     = False,\n",
        "    num_workers             = 0,\n",
        "    fp_16                   = False, \n",
        "    opt_level               = 'O1',\n",
        "    max_grad_norm           = 1.0,\n",
        ")\n",
        "args = argparse.Namespace(**args_dict)\n",
        "logger = TensorBoardLogger(\"tb_logs\", version = 1, name = 'distilbert')\n",
        "\n",
        "pl.seed_everything(42)\n",
        "Distilbert_finetuner = DistilbertFineTuner(args)\n",
        "\n",
        "train_params = dict(\n",
        "    default_root_dir = args.model_dir,\n",
        "    accumulate_grad_batches = 1,\n",
        "    gpus = args.n_gpu,\n",
        "    max_epochs = args.num_train_epochs,\n",
        "    precision = 16 if args.fp_16 else 32,\n",
        "    amp_level = args.opt_level,\n",
        "    resume_from_checkpoint = args.resume_from_checkpoint,\n",
        "    gradient_clip_val = args.max_grad_norm,\n",
        "    val_check_interval = args.val_check_interval,\n",
        "    progress_bar_refresh_rate = 20,\n",
        "    logger = logger\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(**train_params)\n",
        "\n",
        "trainer.fit(Distilbert_finetuner)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 42\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: you passed in a val_dataloader but have no validation_step. Skipping val loop\n",
            "  warnings.warn(*args, **kwargs)\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name             | Type            | Params\n",
            "-----------------------------------------------------\n",
            "0 | model            | DistilBertModel | 66.4 M\n",
            "1 | linear_layer     | Linear          | 590 K \n",
            "2 | classifier_layer | Linear          | 35.7 M\n",
            "3 | dropout          | Dropout         | 0     \n",
            "-----------------------------------------------------\n",
            "102 M     Trainable params\n",
            "0         Non-trainable params\n",
            "102 M     Total params\n",
            "410.513   Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4ded438d34645ffb4febf7a5d316f87",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfj252bghG5k"
      },
      "source": [
        "### 7. Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBB1a9vhhFrM",
        "outputId": "6c758d92-b18b-4e6d-d999-361397388760"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "validation_dataset = ArticlesDataset(validate_df,\n",
        "                                     tokenizer = tokenizer,\n",
        "                                     input_length = input_length)\n",
        "\n",
        "sampler = RandomSampler(validation_dataset)\n",
        "\n",
        "loader = DataLoader(validation_dataset,\n",
        "                  batch_size = 32,\n",
        "                  sampler = sampler,\n",
        "                  num_workers = 2)\n",
        "\n",
        "\n",
        "it = iter(loader)\n",
        "\n",
        "sample_batch = next(it)\n",
        "print(sample_batch[\"input_ids\"].shape)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSRbpSy3hQje",
        "outputId": "c6799628-2535-4b5f-ea34-def262a13505"
      },
      "source": [
        "Distilbert_finetuner.to('cuda')\n",
        "\n",
        "test_outputs = Distilbert_finetuner.forward(\n",
        "    sample_batch[\"input_ids\"].cuda(),\n",
        "    sample_batch[\"attention_mask\"].cuda(),\n",
        "    sample_batch[\"label\"].cuda())\n",
        "\n",
        "print(test_outputs[1].shape)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 46391])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwmXsDYPk8cf",
        "outputId": "152a2e99-da84-4c48-ae6c-c22fcb4aa64a"
      },
      "source": [
        "for index in range(min(len(sample_batch[\"input_ids\"]), 5)):\n",
        "    print(tokenizer.decode(sample_batch[\"input_ids\"][index]))\n",
        "    list_tags_golden = []\n",
        "    list_tags_output = []\n",
        "    for i in range(len(tags_list)):\n",
        "        if sample_batch[\"label\"][index][i] == 1.:\n",
        "            list_tags_golden.append(i)\n",
        "            list_tags_output.append(test_outputs[1][index][i].item())\n",
        "        # if test_outputs[1][index][i] > 0.5:\n",
        "        #     list_tags_output.append(i)\n",
        "\n",
        "    print(list_tags_golden)\n",
        "    print(list_tags_output)\n",
        "\n",
        "    print(\"*\" * 10)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] learning to recognize reliable users and content in social media with coupled mutual reinforcementcommunity question answering ( cqa ) has emerged as a popular forum for users to pose questions for other users to answer. over the last few years, cqa portals such as naver and yahoo! answers have exploded in popularity, and now provide a viable alternative to general purpose web search. at the same time, the answers to past questions submitted in cqa sites comprise a valuable knowledge repository which could be a [SEP]\n",
            "[1896, 2061, 3447, 7754, 9700, 12147, 12832, 13244, 14186, 14493, 14977, 15772, 17782, 22686, 25606, 28485, 28641, 32286, 33433, 35500, 36185, 40928, 41534, 42694]\n",
            "[-0.011366932652890682, 0.006085234694182873, -0.015387983992695808, -0.016205474734306335, -0.011165891773998737, 0.01911221444606781, -0.0015007118927314878, 0.034339889883995056, -0.027376720681786537, 0.017517006024718285, 0.0064484551548957825, -0.03416009247303009, -0.02070225030183792, -0.029210872948169708, -0.008829105645418167, -0.036702629178762436, 0.019923202693462372, -0.0024704469833523035, 0.006836410611867905, 0.023949922993779182, -0.0032558829989284277, 0.009416640736162663, -0.022787446156144142, 0.010619105771183968]\n",
            "**********\n",
            "[CLS] evolutionary games on graphsgame theory is one of the key paradigms behind many scientific disciplines from biology to behavioral sciences to economics. in its evolutionary form and especially when the interacting agents are linked in a specific social network the underlying solution concepts and methods are very similar to those applied in non - equilibrium statistical physics. this review gives a tutorial - type overview of the field for physicists. the first four sections introduce the necessary background in classical and evolutionary game theory from the basic definitions to the most [SEP]\n",
            "[969, 2794, 3163, 4695, 5990, 8421, 10587, 14887, 16833, 18288, 21127, 23076, 27708, 27845, 27881, 28001, 28026, 30698, 31409, 31522, 32229, 34275, 34723, 36825, 38231, 46224]\n",
            "[0.01672542281448841, -0.025974784046411514, -0.018158704042434692, 0.03132791817188263, 0.021842893213033676, -0.005097539164125919, 0.025503264740109444, 0.028272638097405434, -0.010813917964696884, 0.011693690903484821, -0.016521267592906952, 0.02566034346818924, 0.02493833750486374, -0.0037576043978333473, 0.01260768249630928, 0.004863644950091839, -0.008881558664143085, 0.007164275273680687, -0.03379404917359352, -0.010820593684911728, -0.01457231491804123, 0.02199217490851879, -0.02851664274930954, 0.01514887809753418, 0.011392349377274513, -0.016167057678103447]\n",
            "**********\n",
            "[CLS] why aren't operating systems getting faster as fast as hardware? this note evaluates several hardware platforms and operating systems using a set of benchmarks that test memory bandwidth and various operating system features such as kernel entry / exit and file systems. the overall conclusion is that operating system performance does not seem to be improving at the same rate as the base speed of the underlying hardware. copyright a 1989 digital equipment corporation d i g i t a l western research laboratory 100 hamilton avenue palo alto, california [SEP]\n",
            "[2927, 4414, 6680, 9756, 13970, 16298, 17981, 18699, 21504, 25772, 29254, 40166]\n",
            "[0.012278567999601364, -0.035783592611551285, -0.014345243573188782, 0.013055001385509968, 0.03312696889042854, 0.033798929303884506, 0.009678585454821587, -0.002483268268406391, -0.02375994250178337, 0.03527184575796127, -0.004011967685073614, -0.033948030322790146]\n",
            "**********\n",
            "[CLS] evaluating costs of conservationthe loss and fragmentation of native habitats caused by agricultural development and conversion of agricultural lands into urban sprawl are widely recognized as the most serious modern threats to the conservation of biodiversity. regulatory mechanisms have been heavily relied upon but largely ineffective at preventing the loss of wildlife habitat and the decline of endangered species, particularly on private lands. land acquisition and permanent conservation easements may be more reliable conservation tools, but they are often incompatible with the desires of private landowners and rural communities. [SEP]\n",
            "[3412, 5045]\n",
            "[0.027961166575551033, 0.005385475233197212]\n",
            "**********\n",
            "[CLS] niche construction, biological evolution and cultural change. we propose a conceptual model that maps the causal pathways relating biological evolution to cultural change. it builds on conventional evolutionary theory by placing emphasis on the capacity of organisms to modify sources of natural selection in their environment ( niche construction ) and by broadening the evolutionary dynamic to incorporate ontogenetic and cultural processes. in this model, phenotypes have a much more active role in evolution than generally conceived. this sheds light on hominid evolution, [SEP]\n",
            "[]\n",
            "[]\n",
            "**********\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-9haYVc4eQ_"
      },
      "source": [
        "#### TODO:\n",
        "\n",
        "- This model will give us per article classification across all tags.\n",
        "- When any article is added, we can run this model and store the corresponding classification vector.\n",
        "- For a particular user, we can take either the last paper accessed or mean of the papers accessed to construct a tag_vector which can be used to find the nearest matching articles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRaAYq3gWNHW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}